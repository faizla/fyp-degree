{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import training data yg dah cleaned\n",
    "df = pd.read_csv('/Users/faiz/FYPCoding/FYP/newtrainingdata.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    798679\n",
      "0    798479\n",
      "Name: sentiment, dtype: int64\n",
      "1    0.500063\n",
      "0    0.499937\n",
      "Name: sentiment, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# df[df.sentiment == 1] #798478\n",
    "# dfneg = df.iloc[0:20000]\n",
    "# dfpos = df.iloc[798478:818478]\n",
    "# df = pd.concat([dfneg, dfpos], ignore_index=True)\n",
    "#Positive and negative sentiment count\n",
    "print(df.sentiment.value_counts())\n",
    "#Percentage of positive and negative reviews\n",
    "print(df.sentiment.value_counts() / len(df))\n",
    "#df.text.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, ENGLISH_STOP_WORDS \n",
    "\n",
    "#to add new stop word\n",
    "#my_stop_words = ENGLISH_STOP_WORDS.union(['airline', 'airlines', '@'])\n",
    "\n",
    "# Build the vectorizer, specify max features \n",
    "cv = CountVectorizer(ngram_range=(1, 2),token_pattern=r'\\b[^\\d\\W][^\\d\\W]+\\b',\n",
    "                     stop_words=ENGLISH_STOP_WORDS).fit(df.text)\n",
    "\n",
    "# Transform the review column\n",
    "cv_transform = cv.transform(df.text)\n",
    "\n",
    "####SAVE BagOfWords model\n",
    "# save the model to disk\n",
    "filename = 'cv_fitted.sav'\n",
    "pickle.dump(cv, open(filename, 'wb'))\n",
    " \n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "# Create the bow representation\n",
    "# df_cv=pd.DataFrame(cv_transform.toarray(), columns=cv.get_feature_names())\n",
    "# print(df_cv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "####TFIDF \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Define the vectorizer and specify the arguments\n",
    "my_pattern = r'\\b[^\\d\\W][^\\d\\W]+\\b'\n",
    "tvc = TfidfVectorizer(ngram_range=(1, 2),token_pattern=my_pattern, \n",
    "                      stop_words=ENGLISH_STOP_WORDS,sublinear_tf=True).fit(df.text)\n",
    "\n",
    "# Transform the vectorizer\n",
    "tvc_transform = tvc.transform(df.text)\n",
    "\n",
    "####SAVE BagOfWords model\n",
    "# save the model to disk\n",
    "filename = 'tvc_fitted.sav'\n",
    "pickle.dump(tvc, open(filename, 'wb'))\n",
    " \n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "\n",
    "# Transform to a data frame and specify the column names\n",
    "###nk convert ke df kne upgrade ram\n",
    "# df_tvc=pd.DataFrame(tvc_transform.toarray(), columns=tvc.get_feature_names())\n",
    "# print('Top 5 rows of the DataFrame: ', df_tvc.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Performance\n",
      "Accuracy on train set:  0.8918531829202818\n",
      "Accuracy on test set:  0.7752103734128077\n",
      "Confusion matrix test set: \n",
      " [[0.39361116 0.10632623]\n",
      " [0.1184634  0.38159921]]\n",
      "\n",
      "\n",
      "Count Vectorizer Performance\n",
      "Accuracy on train set:  0.8963533652754972\n",
      "Accuracy on test set:  0.7741553757920309\n",
      "Confusion matrix test set: \n",
      " [[0.39273147 0.10720592]\n",
      " [0.11863871 0.3814239 ]]\n"
     ]
    }
   ],
   "source": [
    "# Import the required packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "\n",
    "# Define the vector of labels and matrix of features FOR TFIDF\n",
    "y_tvc = df.sentiment\n",
    "X_tvc = tvc_transform\n",
    "# Define the vector of labels and matrix of features FOR COUNTVECTORIZER\n",
    "y_cv = df.sentiment\n",
    "X_cv = cv_transform\n",
    "\n",
    "# Perform the train-test split FOR TFIDF\n",
    "X_train_tvc, X_test_tvc, y_train_tvc, y_test_tvc = train_test_split(X_tvc, y_tvc, test_size=0.2, random_state=42,stratify=y_tvc)\n",
    "# Perform the train-test split FOR COUNTVECTORIZER\n",
    "X_train_cv, X_test_cv, y_train_cv, y_test_cv = train_test_split(X_cv, y_cv, test_size=0.2, random_state=42,stratify=y_cv)\n",
    "\n",
    "# Build a classification model FOR TFIDF\n",
    "model_tvc = MultinomialNB().fit(X_train_tvc,y_train_tvc)\n",
    "# Build a classification model FOR COUNTVECTORIZER\n",
    "model_cv = MultinomialNB().fit(X_train_cv,y_train_cv)\n",
    "#multinb = MultinomialNB().fit(X_testtvc,y_testtvc)\n",
    "\n",
    "print('TF-IDF Performance')\n",
    "print('Accuracy on train set: ', model_tvc.score(X_train_tvc,y_train_tvc))\n",
    "print('Accuracy on test set: ', model_tvc.score(X_test_tvc,y_test_tvc))\n",
    "y_predicted_tvc = model_tvc.predict(X_test_tvc)\n",
    "print('Confusion matrix test set: \\n', confusion_matrix(y_test_tvc, y_predicted_tvc)/len(y_test_tvc))\n",
    "print()\n",
    "print()\n",
    "print('Count Vectorizer Performance')\n",
    "print('Accuracy on train set: ', model_cv.score(X_train_cv,y_train_cv))\n",
    "print('Accuracy on test set: ', model_cv.score(X_test_cv,y_test_cv))\n",
    "y_predicted_cv = model_cv.predict(X_test_cv)\n",
    "print('Confusion matrix test set: \\n', confusion_matrix(y_test_cv, y_predicted_cv)/len(y_test_cv))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_predicted = model.predict(X_test)\n",
    "\n",
    "# # Predict the probability of the 0 class\n",
    "# prob_0 = log_reg.predict_proba(X_test)[:, 0]\n",
    "# # Predict the probability of the 1 class\n",
    "# prob_1 = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# print(\"First 10 predicted probabilities of class 0: \", prob_0[:10])\n",
    "# print(\"First 10 predicted probabilities of class 1: \", prob_1[:10])\n",
    "# # Print the performance metrics\n",
    "\n",
    "\n",
    "# #####FOR REGULARIZATION\n",
    "# # Train a logistic regression with regularization of 1000\n",
    "# log_reg1 = LogisticRegression(C=1000).fit(X_train, y_train)\n",
    "# # Train a logistic regression with regularization of 0.001\n",
    "# log_reg2 = LogisticRegression(C=0.001).fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7741553757920309\n"
     ]
    }
   ],
   "source": [
    "# save the model to disk\n",
    "filename = 'tvcsent_model.sav'\n",
    "pickle.dump(model_tvc, open(filename, 'wb'))\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'cvsent_model.sav'\n",
    "pickle.dump(model_cv, open(filename, 'wb'))\n",
    " \n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X_test_cv, y_test_cv)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###tvc = TfidfVectorizer(token_pattern=my_pattern, stop_words=ENGLISH_STOP_WORDS,sublinear_tf=True).fit(df.text)\n",
    "\n",
    "Accuracy on train set:  0.7889555350677688\n",
    "Accuracy on test set:  0.7573255027674122\n",
    "Accuracy score test set:  0.7573255027674122\n",
    "Confusion matrix test set: \n",
    " [[0.38130807 0.11862932]\n",
    " [0.12404518 0.37601743]]\n",
    "\n",
    "#tvc = TfidfVectorizer(ngram_range=(1, 2),token_pattern=my_pattern, stop_words=ENGLISH_STOP_WORDS,sublinear_tf=True).fit(df.text)\n",
    "0.7752103734128077\n",
    "Accuracy on train set:  0.8918531829202818\n",
    "Accuracy on test set:  0.7752103734128077\n",
    "Accuracy score test set:  0.7752103734128077\n",
    "Confusion matrix test set: \n",
    " [[0.39361116 0.10632623]\n",
    " [0.1184634  0.38159921]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###cv = CountVectorizer(token_pattern=r'\\b[^\\d\\W][^\\d\\W]+\\b',stop_words=ENGLISH_STOP_WORDS)\n",
    "Accuracy on train set:  0.7895315584092364\n",
    "Accuracy on test set:  0.7637431440807433\n",
    "Accuracy score test set:  0.7637431440807433\n",
    "Confusion matrix test set: \n",
    " [[0.38525257 0.11468482]\n",
    " [0.12157204 0.37849057]]\n",
    "\n",
    "\n",
    "#cv = CountVectorizer(ngram_range=(1, 2),token_pattern=r'\\b[^\\d\\W][^\\d\\W]+\\b',stop_words=ENGLISH_STOP_WORDS)\n",
    "0.7741553757920309\n",
    "Accuracy on train set:  0.8963533652754972\n",
    "Accuracy on test set:  0.7741553757920309\n",
    "Accuracy score test set:  0.7741553757920309\n",
    "Confusion matrix test set: \n",
    " [[0.39273147 0.10720592]\n",
    " [0.11863871 0.3814239 ]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
